# Natural Language Processing - Assignment 3 - Russian Nested Named Entities Recognition

## Solutions

### Dictionary-based approach

This approach uses a simple dictionary to store the entities and their corresponding labels. Each token for the dictionary is stemmed, if the token is a list of words, then each word is stemmed and then joined.

The dictionary is then used to predict the labels for the test data. Candidates for the checking are generated by n-grams. Each n-gram is processed in the same way as the training data. The n-grams are then checked against the dictionary to predict the labels.

#### Detailed pipeline

1. Load the training data.
2. Preprocess the training data with `razdel` and `snowballstemmer`.
3. Create a dictionary of entities and their corresponding labels.
4. Generate candidates for the test data using n-grams.
5. Predict the labels for the test data using the dictionary.

### SpaCy SpanCat approach

This approach uses the SpaCy library to train a Span Categorization (SpanCat) model. The training data is converted to the IOB2 format and then to the SpaCy format. The model is then trained and evaluated.

This model consists of two parts:

- a suggester - a model that suggests possible spans for the entity
- and a classifier - a model that classifies the suggested spans into the correct label.

The classifier itself has three steps: Embedding, Pooling, and Scoring.

- Embedding obtains numerical representations (tok2vec) for candidate spans;
- Pooling reduces sequences for robustness, encode context with a window encoder;
- Scoring rerforms multi-label classification on pooled spans to obtain predictions and label probabilities.

### Merge of both approaches

The final solution is a merge of both approaches. Both the dictionary-based and spaCy SpanCat models are used to predict the labels for the test data. The predictions are then merged and filtered to get the final result.

### Results

| Solution | Codalab Score |
| --- | --- |
| Dictionary-based approach | 0.42 |
| SpaCy SpanCat approach | 0.27 |
| Merge of both approaches | **0.46** |
