# Natural Language Processing - Assignment 3 - Russian Nested Named Entities Recognition

## Solutions

### Dictionary-based approach

This approach uses a simple dictionary to store the entities and their corresponding labels. Each token for the dictionary is stemmed, if the token is a list of words, then each word is stemmed and then joined.

The dictionary is then used to predict the labels for the test data. Candidates for the checking are generated by n-grams. Each n-gram is processed in the same way as the training data. The n-grams are then checked against the dictionary to predict the labels.

#### Detailed pipeline

1. Load the training data.
2. Preprocess the training data with `razdel` and `snowballstemmer`.
3. Create a dictionary of entities and their corresponding labels.
4. Generate candidates for the test data using n-grams.
5. Predict the labels for the test data using the dictionary.

### SpaCy SpanCat approach

This approach uses the SpaCy library to train a Span Categorization (SpanCat) model. The training data is converted to the IOB2 format and then to the SpaCy format. The model is then trained and evaluated.

IOB2 format used during training has the following structure:

```text
TOKEN \t IOB2_TAG \t IOB2_TAG \t IOB2_TAG \t IOB2_TAG \n
TOKEN \t IOB2_TAG \t IOB2_TAG \t IOB2_TAG \t IOB2_TAG \n
...
```

The token is followed by 4 (default) IOB2 tags (parallel stacks) separated by tabs. The tags are in the format `B-LABEL` for the beginning of the entity, `I-LABEL` for the inside of the entity, and `O` for outside of the entity.

Number of parallel stacks can be changed by setting the `MAX_STACK` parameter in the `scripts/constants.py` file.

This model consists of two parts:

- a suggester - a model that suggests possible spans for the entity
- and a classifier - a model that classifies the suggested spans into the correct label.

The classifier itself has three steps: Embedding, Pooling, and Scoring.

- Embedding obtains numerical representations (tok2vec) for candidate spans;
- Pooling reduces sequences for robustness, encode context with a window encoder;
- Scoring rerforms multi-label classification on pooled spans to obtain predictions and label probabilities.

### Merge of both approaches

The final solution is a merge of both approaches. Both the dictionary-based and spaCy SpanCat models are used to predict the labels for the test data. The predictions are then merged and filtered to get the final result.

This approach achieved the best F1 score of **0.53**. This is likely because the dictionary-based approach effectively tags common entities from the dictionary, while the SpanCat model tackles unseen entities using its trained NLP model.

### Results

| Solution | Codalab Score |
| --- | --- |
| Dictionary-based approach | 0.49 |
| SpaCy SpanCat approach | 0.45 |
| Merge of both approaches | **0.53** |

The relatively low F1 score of the SpanCat model (0.45) may be due to several factors:

- Imbalanced training dataset. The model may struggle to generalize effectively to underrepresented classes.
- Tokenization and text preprocessing. Meaning, that the way the text is expected to be tokenized internally on the Codalab platform may differ from the steps taken during training, leading to a mismatch and degraded performance.
- Hyperparameter tuning. The hyperparameters used for training the SpanCat model may not be optimal for this particular dataset and task, and further tuning could potentially improve the results.
